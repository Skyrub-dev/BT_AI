{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Skyy-Dev/BT_AI/blob/main/BT_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITl913RrtYZL"
      },
      "source": [
        "# **L6 End-of-year project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RKzqSqO5qgV"
      },
      "source": [
        "**Import Files**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "z4hrSFDsGduZ",
        "outputId": "316d7094-df05-4958-a33c-cda7530d3789"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-272d4cbdf5cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mnormed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must be in a directory that exists'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m   \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_signal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGKILL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must be in a directory that exists"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/MyDrive/data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YVuh3Om96VN",
        "outputId": "0faccdd4-0e53-4eb0-b789-ffbf2aa57d53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9XM_FtFdp8_"
      },
      "source": [
        "**Alternatively, through a local machine**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYtdUe3Rd2C8"
      },
      "outputs": [],
      "source": [
        "local_dir = '../Archive'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU8Icm6DY3gV"
      },
      "source": [
        "Before proceeding, check that the directory can be found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BFYXMEKY3gV",
        "outputId": "79ab8b96-226a-41a6-8621-9ded0b816fb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-55bad8a77143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'local_dir' is not defined"
          ]
        }
      ],
      "source": [
        "os.listdir(local_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAHBNGLj5_tt"
      },
      "source": [
        "**Importing libraries**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z80tFMw8eF2G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2 #checkout open cv\n",
        "import imghdr #allows to check file extensions for images\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "#import scipy\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#import kaggle - will likely change\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras.models import sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlEfSL8f2Eok"
      },
      "source": [
        "GPU check optimisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQ74ovch2GCk"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja8EYaeISnEg"
      },
      "source": [
        "CPU / GPU debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6wztOusSuA1",
        "outputId": "7942747d-d2ac-45e5-cf7d-599567e10df8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.config.list_physical_devices(device_type=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xwK85HmsRaT"
      },
      "source": [
        "**If running off a local machine, this line of code must be run to install all dependencies**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i23KPhcisdD7",
        "outputId": "2de4c2d6-313c-4cd3-a1df-8fb56fc0c5a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.29.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "  Downloading tensorflow_gpu-2.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow_gpu-2.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow_gpu-2.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.9.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install tensorflow tensorflow-gpu opencv-python matplotlib #! || % at the beginning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN60NljZq1_c"
      },
      "source": [
        "**Importing and loading the data**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6XRz8vUswae"
      },
      "source": [
        "To import our data, we're going to be using an approach known as \"Supervised learning\". This is defined through pre-labelled datasets which the AI will be trained on. This is the best approach to solve a classification problem as the model can adjust itself and learn from its mistakes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrsCD9TS26Lt"
      },
      "source": [
        "https://www.youtube.com/watch?v=_L2uYfVV48I\n",
        "\n",
        "This is something that you do only for toy datasets or small sample sets. In the reality using image data generator is not recommended when you have huge volumes of images or video frames (which is usually the case). In those cases is a good practice to load and split the data across multiple tfrecords, then loading it progressively with tf.data and perform multithreaded augmentations dynamically during training. The majority of the augmentations can be computed using low level tf or common python functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqHD8gInq9Lo"
      },
      "outputs": [],
      "source": [
        "labels = ['giloma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH9nl4esw2Ws"
      },
      "source": [
        "**Loading the images**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEQV_i18Y3gh"
      },
      "source": [
        "**When using Colab, run the following lines of code from Google drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rLf1DwtKY3gi"
      },
      "outputs": [],
      "source": [
        "testing_path = '/content/drive/MyDrive/data/archive/Testing'\n",
        "training_path = '/content/drive/MyDrive/data/archive/Training'\n",
        "validation_path = '/content/drive/MyDrive/data/archive/Validation'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO4Euhf0Y3gj"
      },
      "source": [
        "**If using the downloaded local file, run these lines of code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRg9HgRGY3gj"
      },
      "outputs": [],
      "source": [
        "testing_path = '../Archive/Testing/'\n",
        "training_path = '../Archive/Training/'\n",
        "validation_path = '../Archive/Validation/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0vWjgUDZXox"
      },
      "source": [
        "Do **NOT** run them both, this will cause errors, only run the one which is applicable to you"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performing a validation split**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "jkbF_f2ZsJh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation is typically recommended to be split 80/20"
      ],
      "metadata": {
        "id": "uc2FHuAcsOjn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESSJtE1_eIA"
      },
      "source": [
        "Splitting data into testing, training and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "merjq1--_eIB",
        "outputId": "76d3de0a-85e7-4e99-d4d9-033799518933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 394 files belonging to 4 classes.\n",
            "Found 2870 files belonging to 4 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-43678a790fff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m validgen = tf.keras.preprocessing.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'inferred'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     image_paths, labels, class_names = dataset_utils.index_directory(\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    544\u001b[0m                     \u001b[0;34m\"The `class_names` passed did not match the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0;34m\"names of the subdirectories of the target directory. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The `class_names` passed did not match the names of the subdirectories of the target directory. Expected: [], but received: ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']"
          ]
        }
      ],
      "source": [
        "testgen = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory = testing_path,\n",
        "    labels = 'inferred',\n",
        "    label_mode= 'categorical',\n",
        "    class_names = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor'],\n",
        "    batch_size = 32,\n",
        "    image_size = (150, 150),\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "traingen = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory = training_path,\n",
        "    labels = 'inferred',\n",
        "    label_mode= 'categorical',\n",
        "    class_names = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor'],\n",
        "    batch_size = 32,\n",
        "    image_size = (150, 150),\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "validgen = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory = validation_path,\n",
        "    labels = 'inferred',\n",
        "    label_mode= 'categorical',\n",
        "    class_names = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor'],\n",
        "    batch_size = 32,\n",
        "    image_size = (150, 150),\n",
        "    shuffle = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://ibrahimsobh.github.io/kaggle-COVID19-Classification/\n",
        "#https://www.datacamp.com/tutorial/complete-guide-data-augmentation\n",
        "#https://kylewbanks.com/blog/train-validation-split-with-imagedatagenerator-keras"
      ],
      "metadata": {
        "id": "euSJF5lK-XIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL9s954SlLvg",
        "outputId": "b3cc7239-713d-417d-b462-ba70f01436bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 294 images belonging to 4 classes.\n",
            "Found 2044 images belonging to 4 classes.\n",
            "Found 0 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "#https://studymachinelearning.com/keras-imagedatagenerator-with-flow_from_directory/\n",
        "#https://stackoverflow.com/questions/54263218/cnn-divide-images-into-training-validation-testing\n",
        "\n",
        "img_size = 150 #Likely not necessary but could be used\n",
        "\n",
        "classes = 4\n",
        "#Normalising pixel values to be between 0 and 1\n",
        "testing_data_generator = ImageDataGenerator(rescale = 1./255)\n",
        "training_data_generator = ImageDataGenerator(rescale = 1./255)\n",
        "validation_data_generator = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "testing_generator = testing_data_generator.flow_from_directory (testing_path,\n",
        "                                                                target_size = (150, 150),\n",
        "                                                                color_mode = 'rgb',\n",
        "                                                                save_format = 'jpg',\n",
        "                                                                batch_size = 32,\n",
        "                                                                class_mode = 'categorical', #Automatically converts the class labels to a one-hot encoded form\n",
        "                                                                classes = ['giloma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor'])\n",
        "\n",
        "#Need to check these two and make sure they're configured correctly\n",
        "\n",
        "training_generator = training_data_generator.flow_from_directory (training_path,\n",
        "                                                                target_size = (150, 150),\n",
        "                                                                color_mode = 'rgb',\n",
        "                                                                save_format = 'jpg',\n",
        "                                                                batch_size = 32,\n",
        "                                                                class_mode = 'categorical',\n",
        "                                                                shuffle = True, #Prevents overfitting but when evaluating model keep the data in its original order\n",
        "                                                                subset = 'training',\n",
        "                                                                #validation_split = 0.2,\n",
        "                                                                classes = ['giloma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor'])\n",
        "\n",
        "validation_generator = testing_data_generator.flow_from_directory (validation_path,\n",
        "                                                                target_size = (150, 150),\n",
        "                                                                color_mode = 'rgb',\n",
        "                                                                save_format = 'jpg',\n",
        "                                                                batch_size = 32,\n",
        "                                                                class_mode = 'categorical',\n",
        "                                                                shuffle = True,\n",
        "                                                                subset = 'validation',\n",
        "                                                                classes = ['giloma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grabs data from the batch"
      ],
      "metadata": {
        "id": "I9NXEFXvA7A4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RLCtifJw_eIC"
      },
      "outputs": [],
      "source": [
        "batch = images, labels = next(training_generator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_generator.class_indices.keys() # https://stackoverflow.com/questions/48373685/keras-imagedatagenerator-how-to-get-all-labels-from-data#51652128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alSFoLj9FSfT",
        "outputId": "b8352697-7693-49a6-8ab1-b2e3b1ac5b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['giloma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor'])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_images = images.shape[0] #May remove"
      ],
      "metadata": {
        "id": "k9CPOCu9_-Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_labels = ['giloma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']"
      ],
      "metadata": {
        "id": "UEyW7EPej9KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NEED TO REWORK THIS - JUST AN EXAMPLE\n",
        "for i in range(num_images):\n",
        "  image = images[i]\n",
        "  label = labels[i]\n",
        "\n",
        "  label_index = label.argmax()\n",
        "\n",
        "  class_name = ['giloma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor'][label_index]\n",
        "\n",
        "  plt.imshow(image)\n",
        "  plt.title(class_name)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "UJjVeUw3ACI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for i in range(num_images):\n",
        "  \n",
        "\n",
        "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
        "fig.text(s='Batch images', size = 18, fontweight = 'bold', fontname = 'monospace', y=0.62, x=0.4, alpha=0.8)\n",
        "for i in range(4):\n",
        "  image = images[i]\n",
        "  label = labels[i]\n",
        "  label_index = label.argmax()\n",
        "  class_name = ['giloma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor'][label_index]\n",
        "  ax[i].imshow(images[i])\n",
        "  ax[i].set_title(class_name)\n",
        "\n",
        "if class_name == ground_truth_labels[i]:\n",
        "    print(f\"IGNORE THIS BECAUSE IT'S WRONG\")\n",
        "    print(f\"Image {i + 1} is correctly labelled as {class_name}\")\n",
        "else:\n",
        "    print(f\"Image {i + 1} is incorrectly labelled as {class_name}, the ground truth label is {ground_truth_labels[i]}\")\n",
        "#plt.imshow(image)\n",
        "#plt.title(class_name)\n",
        "#plt.show()\n",
        "#for idx, img in enumerate(batch[0][:4]):\n",
        "  #ax[idx].imshow(image)\n",
        "  #ax[idx].title.set_text(class_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HMdoR19sBYtw",
        "outputId": "8e76b994-c6c1-48a7-8aca-a30c40bcd859"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5c19372f4658>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Batch images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bold'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'monospace'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.62\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mlabel_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the model"
      ],
      "metadata": {
        "id": "Msz_AU6Lrxl-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zM77-N-k_eIC"
      },
      "outputs": [],
      "source": [
        "for images, labels in testgen.batch(batch_size = 32):\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcClxlpX_eIC",
        "outputId": "c8fc82f2-024b-4dac-c607-e1624ca2ef51"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'scipy' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x \u001b[39m=\u001b[39m testing_generator\u001b[39m.\u001b[39mnext()\n",
            "File \u001b[1;32mc:\\Users\\tomke\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:168\u001b[0m, in \u001b[0;36mIterator.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m     index_array \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_generator)\n\u001b[0;32m    166\u001b[0m \u001b[39m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m# so it can be done in parallel\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_batches_of_transformed_samples(index_array)\n",
            "File \u001b[1;32mc:\\Users\\tomke\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:384\u001b[0m, in \u001b[0;36mBatchFromFilesMixin._get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_data_generator:\n\u001b[0;32m    383\u001b[0m     params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_data_generator\u001b[39m.\u001b[39mget_random_transform(x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m--> 384\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimage_data_generator\u001b[39m.\u001b[39;49mapply_transform(x, params)\n\u001b[0;32m    385\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_data_generator\u001b[39m.\u001b[39mstandardize(x)\n\u001b[0;32m    386\u001b[0m batch_x[i] \u001b[39m=\u001b[39m x\n",
            "File \u001b[1;32mc:\\Users\\tomke\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:2013\u001b[0m, in \u001b[0;36mImageDataGenerator.apply_transform\u001b[1;34m(self, x, transform_parameters)\u001b[0m\n\u001b[0;32m   2010\u001b[0m img_col_axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol_axis \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   2011\u001b[0m img_channel_axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchannel_axis \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 2013\u001b[0m x \u001b[39m=\u001b[39m apply_affine_transform(\n\u001b[0;32m   2014\u001b[0m     x,\n\u001b[0;32m   2015\u001b[0m     transform_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtheta\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m),\n\u001b[0;32m   2016\u001b[0m     transform_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m),\n\u001b[0;32m   2017\u001b[0m     transform_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mty\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m),\n\u001b[0;32m   2018\u001b[0m     transform_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mshear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m),\n\u001b[0;32m   2019\u001b[0m     transform_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mzx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m1\u001b[39;49m),\n\u001b[0;32m   2020\u001b[0m     transform_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mzy\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m1\u001b[39;49m),\n\u001b[0;32m   2021\u001b[0m     row_axis\u001b[39m=\u001b[39;49mimg_row_axis,\n\u001b[0;32m   2022\u001b[0m     col_axis\u001b[39m=\u001b[39;49mimg_col_axis,\n\u001b[0;32m   2023\u001b[0m     channel_axis\u001b[39m=\u001b[39;49mimg_channel_axis,\n\u001b[0;32m   2024\u001b[0m     fill_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfill_mode,\n\u001b[0;32m   2025\u001b[0m     cval\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcval,\n\u001b[0;32m   2026\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation_order,\n\u001b[0;32m   2027\u001b[0m )\n\u001b[0;32m   2029\u001b[0m \u001b[39mif\u001b[39;00m transform_parameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mchannel_shift_intensity\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2030\u001b[0m     x \u001b[39m=\u001b[39m apply_channel_shift(\n\u001b[0;32m   2031\u001b[0m         x,\n\u001b[0;32m   2032\u001b[0m         transform_parameters[\u001b[39m\"\u001b[39m\u001b[39mchannel_shift_intensity\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   2033\u001b[0m         img_channel_axis,\n\u001b[0;32m   2034\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\tomke\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\preprocessing\\image.py:2529\u001b[0m, in \u001b[0;36mapply_affine_transform\u001b[1;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[0;32m   2485\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkeras.preprocessing.image.apply_affine_transform\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2486\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_affine_transform\u001b[39m(\n\u001b[0;32m   2487\u001b[0m     x,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2499\u001b[0m     order\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   2500\u001b[0m ):\n\u001b[0;32m   2501\u001b[0m     \u001b[39m\"\"\"Applies an affine transformation specified by the parameters given.\u001b[39;00m\n\u001b[0;32m   2502\u001b[0m \n\u001b[0;32m   2503\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2527\u001b[0m \u001b[39m        ImportError: if SciPy is not available.\u001b[39;00m\n\u001b[0;32m   2528\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2529\u001b[0m     \u001b[39mif\u001b[39;00m scipy \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2530\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m   2531\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mImage transformations require SciPy. \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInstall SciPy.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2532\u001b[0m         )\n\u001b[0;32m   2534\u001b[0m     \u001b[39m# Input sanity checks:\u001b[39;00m\n\u001b[0;32m   2535\u001b[0m     \u001b[39m# 1. x must 2D image with one or more channels (i.e., a 3D tensor)\u001b[39;00m\n\u001b[0;32m   2536\u001b[0m     \u001b[39m# 2. channels must be either first or last dimension\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'scipy' is not defined"
          ]
        }
      ],
      "source": [
        "x = testing_generator.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmuvPyQg_eID",
        "outputId": "2e79ec4f-210a-4b71-9839-d34070233c80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testing_path[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5875GGVK_eIE",
        "outputId": "51631196-be74-468e-ead2-6f41a949b51a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'testing_data_generator' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mto_categorical(testing_data_generator, num_classes\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muint8\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'testing_data_generator' is not defined"
          ]
        }
      ],
      "source": [
        "tf.keras.utils.to_categorical(testing_data_generator, num_classes=4, dtype=\"uint8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh1E02Cjwxqo"
      },
      "source": [
        "Test code below, can delete or use as backup if things go wrong"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "MkCyI6yJiQno",
        "outputId": "951291b9-764b-4d18-fe06-6c625b684970"
      },
      "outputs": [
        {
          "ename": "error",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-99c3932628ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m \u001b[0;31m#normalisation if above chunk of code works, will likely not need to apply this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/imgproc/src/resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ],
      "source": [
        "training = []\n",
        "training_label = []\n",
        "\n",
        "testing = []\n",
        "testing_label = []\n",
        "\n",
        "#test_path = os.listdir('/content/drive/MyDrive/data/archive/Training')\n",
        "\n",
        "for i in testing_path:\n",
        "  image = cv2.imread(testing_path, cv2.IMREAD_COLOR)\n",
        "  image = cv2.resize(image, (150, 150))\n",
        "  image = image / 255.0 #normalisation if above chunk of code works, will likely not need to apply this\n",
        "  testing.append(image)\n",
        "  testing_label.append(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBhvVA5Tw6gf"
      },
      "source": [
        "Next I'll likely use Keras’ ImageDataGenerator function to augment the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbpxOKv9xCtJ"
      },
      "outputs": [],
      "source": [
        "#Example: https://studymachinelearning.com/keras-imagedatagenerator-with-flow_from_directory/\n",
        "#src_path_train = \"data/train/\"\n",
        "#src_path_test = \"data/test/\"\n",
        "\n",
        "#adjust this function\n",
        "\n",
        "data_agument = ImageDataGenerator(\n",
        "    rotation_range = 20,\n",
        "    zoom_range = 0.05,\n",
        "    width_shift_range = 0.05,\n",
        "    height_shift_range = 0.05,\n",
        "    shear_range = 0.05,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest',\n",
        "    validation_split = 0.20\n",
        ")\n",
        "\n",
        "#train_datagen = ImageDataGenerator(\n",
        "        #rescale=1 / 255.0,\n",
        "        #rotation_range=20,\n",
        "        #zoom_range=0.05,\n",
        "        #width_shift_range=0.05,\n",
        "        #height_shift_range=0.05,\n",
        "        #shear_range=0.05,\n",
        "        #horizontal_flip=True,\n",
        "        #fill_mode=\"nearest\",\n",
        "        #validation_split=0.20)\n",
        "\n",
        "#test_datagen = ImageDataGenerator(rescale=1 / 255.0)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "46bfae0556cc79fc827cf62550d4b72d149cdfc64787c68439fc9ea0697c8cac"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}